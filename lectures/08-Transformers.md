## Transformers

### Required Study Materials

- [LSTM is dead. Long Live Transformers](https://www.youtube.com/watch?v=S27pHKBEp30)
- [Attention is all you need](https://www.youtube.com/watch?v=rBCqOTEfxvg)
- [Attention is all you need paper](https://arxiv.org/pdf/1706.03762.pdf) - the original paper if anyone is curious. We don't expect people to read it and understand it, but it might be interesting for you to just have a look inside.
- alternative / supportive reading with pictures [Illustrated transformers](https://jalammar.github.io/illustrated-transformer/)

### Activities

#### 1. Short talk about AlphaFold
We did a short intro to protein structure prediction research and presented how transformer and attention ideas can be used in totally different field than NLP. You can check [AlphaFold webpage](https://alphafold.ebi.ac.uk/), it's pretty interesting.

#### 2. Greeting equivalents
Shorter group exercise about difficulty of translation and necessity of some context. 
Start with listing English greetings such as "Hello", "Hi" and "Good morning". 
Ask people to add greetings in languages they know. 
Show that some greetings are equivalent only in some situations and contexts,
eg. Czech "Ahoj" and English "Hello" is equivalent when greeting a friend,
but one does not say "Ahoj" to a shop assistant (you would rather use "Dobr√Ω den") even though you can use "Hello" in English.

#### 3. Fill in one word

- activity in smaller groups
- ask students to prepare a shorter text (eg. 3 - 5 sentences) and find one word, that is hard to guess if you don't have the full context but just one sentence / part of the sentence
- {Example: I watched the **weather** carefully. We wanted to go on a trip tomorrow and if there was a high chance of rain, we would probably cancel it.} 
- find other words in the text that have stronger relation to the chosen word and highlight them
- rewrite only small part of the text (one sentence) and mask the chosen word. Let other groups guess what should be there
- now give other groups the full text with highlighted context and let them guess again. Are they closer with th guess?

#### 4. Exploring Hugging Face

Open space for exploring and playing. Show them [HuggingFace](https://huggingface.co/) - community and platform for data science and machine learning where you can easily share models and datasets 

*Examples of Hugging Face models to play with:*

https://huggingface.co/roberta-base

https://huggingface.co/albert-base-v2

https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis?

https://huggingface.co/m-newhauser/distilbert-political-tweets?

https://huggingface.co/openai-gpt

https://huggingface.co/gpt2
